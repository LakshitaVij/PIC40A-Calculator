{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d162c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/ashwinivij/anaconda3/lib/python3.11/site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl.metadata\n",
      "  Downloading pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: setuptools in /Users/ashwinivij/anaconda3/lib/python3.11/site-packages (68.0.0)\n",
      "Collecting setuptools\n",
      "  Obtaining dependency information for setuptools from https://files.pythonhosted.org/packages/bb/e1/ed2dd0850446b8697ad28d118df885ad04140c64ace06c4bd559f7c8a94f/setuptools-69.0.2-py3-none-any.whl.metadata\n",
      "  Downloading setuptools-69.0.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: wheel in /Users/ashwinivij/anaconda3/lib/python3.11/site-packages (0.38.4)\n",
      "Collecting wheel\n",
      "  Obtaining dependency information for wheel from https://files.pythonhosted.org/packages/fa/7f/4c07234086edbce4a0a446209dc0cb08a19bb206a3ea53b2f56a403f983b/wheel-0.41.3-py3-none-any.whl.metadata\n",
      "  Downloading wheel-0.41.3-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-69.0.2-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.5/819.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.41.3-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.38.4\n",
      "    Uninstalling wheel-0.38.4:\n",
      "      Successfully uninstalled wheel-0.38.4\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 68.0.0\n",
      "    Uninstalling setuptools-68.0.0:\n",
      "      Successfully uninstalled setuptools-68.0.0\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires PyYAML==6.0.1, but you have pyyaml 6.0 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pip-23.3.1 setuptools-69.0.2 wheel-0.41.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5391c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/ashwinivij/.local/lib/python3.11/site-packages (2.13.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[44 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/_vendor/packaging/requirements.py\", line 35, in __init__\n",
      "  \u001b[31m   \u001b[0m     parsed = _parse_requirement(requirement_string)\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
      "  \u001b[31m   \u001b[0m     return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
      "  \u001b[31m   \u001b[0m     url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 126, in _parse_requirement_details\n",
      "  \u001b[31m   \u001b[0m     marker = _parse_requirement_marker(\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 147, in _parse_requirement_marker\n",
      "  \u001b[31m   \u001b[0m     tokenizer.raise_syntax_error(\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/_vendor/packaging/_tokenizer.py\", line 165, in raise_syntax_error\n",
      "  \u001b[31m   \u001b[0m     raise ParserSyntaxError(\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/g4/tqb_hjc926l926cttvcj3ws80000gn/T/pip-install-bniyggn7/tensorflow-gpu_2eea904802334889bf3a6cc05c836e4d/setup.py\", line 40, in <module>\n",
      "  \u001b[31m   \u001b[0m     setuptools.setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/__init__.py\", line 102, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/__init__.py\", line 73, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/dist.py\", line 629, in parse_config_files\n",
      "  \u001b[31m   \u001b[0m     self._finalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/dist.py\", line 364, in _finalize_requires\n",
      "  \u001b[31m   \u001b[0m     self._normalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/dist.py\", line 379, in _normalize_requires\n",
      "  \u001b[31m   \u001b[0m     self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "  \u001b[31m   \u001b[0m                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ashwinivij/anaconda3/lib/python3.11/site-packages/setuptools/_vendor/packaging/requirements.py\", line 37, in __init__\n",
      "  \u001b[31m   \u001b[0m     raise InvalidRequirement(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b48246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 16:03:29.757698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: <A2C1FEB3-695E-3602-8BDD-E1F4CD92F764> /Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: tried: '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coordination_config_pb2\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rewriter_config_pb2\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/pywrap_tfe.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tfe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: <A2C1FEB3-695E-3602-8BDD-E1F4CD92F764> /Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: tried: '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/ashwinivij/opt/anaconda3/envs/testenv/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11935fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c93c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"opencv-python-headless<4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # computer vision module\n",
    "import imghdr #allow us to check the file extensions of our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'alzdata'\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f2dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93463ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"opencv-python-headless<4.3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    image_class_dir = os.path.join(data_dir, image_class)\n",
    "    if not os.path.isdir(image_class_dir):\n",
    "        continue\n",
    "    #print(image_class)\n",
    "    for images in os.listdir(os.path.join(data_dir,image_class)):\n",
    "            image_path = os.path.join(data_dir, image_class,images)\n",
    "            try:\n",
    "                img = cv2.imread(image_path)\n",
    "                tip = imghdr.what(image_path)\n",
    "                if tip not in image_exts:\n",
    "                    print(\"Image not in ext list {}\".format(image_path)) \n",
    "                    os.remove(image_path)\n",
    "            except Exception as e:\n",
    "                print(\"Issue with image {}\".format(image_path))\n",
    "                        \n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('alzdata','Demented', 'nonDem2248.jpg'))\n",
    "print(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8320668",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0383a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.list_files #allows you to build a data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e167310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efd2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('alzdata') #keras data pipeline, builds an image dataset for you\n",
    "#will do a bunch of preprocesing, like image resizing, for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator() #allows us to access the generator from our data pipeline , allowing us to loop thru the data pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffef49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next() #allowing us to grab a batch back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch) #batch of data\n",
    "#the 2 reps the 2 parts of the image --> image itself and label\n",
    "#first number is images from our directory loaded into memory as a set of numpy arrays\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea829aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('alzdata') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e02428",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=4,figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('alzdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y:(x/255,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0081fb",
   "metadata": {},
   "source": [
    "data = data.map(lambda x,y:(x/255,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = batch[0]/254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4bd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator = data.as_numpy_iterator()\n",
    "print(scaled_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc644892",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=4,figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f32636",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a47169",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = int(len(data)*0.7)\n",
    "valSize = int(len(data)*0.2)+1 #to make it all equal to 9\n",
    "testSize = int(len(data)*0.1)+1 #adding one because rn its 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64506b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(trainSize)\n",
    "val = data.skip(trainSize).take(valSize)\n",
    "test = data.skip(trainSize + valSize).take(testSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24957180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential #great if you have one data input and one data output , if you need something quik and easy\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b906ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c33a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76978f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensor_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2963686",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss visualisation\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label ='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label ='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.xlabel('Iterations/Epochs')  # Updated x label\n",
    "plt.ylabel('Loss') \n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acuracy visualisation\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label ='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label ='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.xlabel('Iterations/Epochs')  # Updated x label\n",
    "plt.ylabel('Accuracy') \n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba803008",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): #run thru testing batches to measure how good the performance of this model is\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24889c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('normalbraincopy copy.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212add1d",
   "metadata": {},
   "source": [
    "np.expand_dims(resize,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d40274",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat<0.5:\n",
    "    print(f'This patient may have alzheimers')\n",
    "else:\n",
    "    print(f'This patient has a healthy brain')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06961038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('normalbrain.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6586d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat<0.5:\n",
    "    print(f'This patient may have alzheimers')\n",
    "else:\n",
    "    print(f'This patient has a healthy brain')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('alzbrainnorm.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef249bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727833e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat>0.5:\n",
    "    print(f'This patient may have alzheimers')\n",
    "else:\n",
    "    print(f'This patient has a healthy brain')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eac54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('alzbrain.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338496ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat>0.5:\n",
    "    print(f'This patient may have alzheimers')\n",
    "else:\n",
    "    print(f'This patient has a healthy brain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f3fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f327e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a9a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f654d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93868b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
